# 以下由夏嘉怡完成

# 8

### 在不确定状态识别的多个记录系统中估计种群大小

Davide Di Cecco

*Istat**，意大利罗马国家统计研究所*



内容

8.1介绍..........................................................169

8.2之前的潜在的类模型.......................172

8.2.1可分解的模型..................................... 174

8.2.2可识别性............................................... 176

8.2.3 EM算法............................................... 176

8.2.4修正参数.......................................... 178

8.2.5不同组件的混合物....................... 178

8.2.6模型选择............................................. 179

8.3观测到的捕获概率的异质性.................181

​       8.3.1协变量的使用…………………………………………182

​	      8.3.2不完整的列表.............................................186

8.4 评估潜在类A贝叶斯方法的解释………………………186

8.5

​        8.5.1 密度算法…………………………189

​        8.5.2 模拟结果…………………………191



### 8.1 介绍

​	我们考虑通过整合多个数据源来估计感兴趣的总体(或“目标群体”)的大小的问题。每个数据源都提供了我们总体的单位列表。在此背景下，我们确定了三种可能的场景:

1.我们目标人群的每个单位都包含在至少一个来源中，但单位的识别并非没有错误:一些范围外的单位被错误地列入名单，反之亦然，我们人口中的一些单位被错误地确定为范围外;

 2.所有观察到的单位都被正确地识别为属于或不属于目标人群。然而，有些单位没有在任何可用的来源中被征募。所以，我们的名单存在覆盖不足的问题;

 3.不是所有的单位都包含在手边的数据和观察到的单位中不能根据目标人群正确分类。

​	第一种情况基本上可以被定性为错误分类的情况。我们可以利用我们所掌握的信息冗余，通过对冗余的随机性做一些假设来估计错误分类错误，因此，我们甚至可以估计出属于目标人群的单位级概率。

​	第二个场景代表捕获-再捕获设置的典型情况，其中我们有一组不完整的列表(它们不覆盖所有单元，并且一些未观察到的单元没有在任何列表中注册)和重叠的列表(一个单元可以在多个源中注册)。被捕获的事件对应于在列表中被注册的事件。与前面的场景不同，我们可以只估计未被观察到的单元的数量。

​	在第三种场景中，也就是本章的重点，我们假设检测的不确定性和状 态识别的不确定性这两个问题都存在于手头的数据中。我们本质上是指一个捕获-再捕获设置，在这个设置中，单位识别中没有错误的经典假设是放松的。在这种情况下，错误分类错误可以被重新表述为“错误捕获”。

​	请注意，在我们正在考虑的捕获-再捕获设置中，捕获不受研究人员控制。事实上，捕获场合由通常为不同目的而设置的报告系统的集合组成。从广义上讲，被一个来源报道的事实，反映的是一个具有行政性质的事件。

​	被错误捕获的原因可能有几种。一般来说，各种来源的范围可能会有很大的不同，可能会与我们的目标人群有所不同。所以，每个列表都可能包 含不同的范围外单元的亚群。范围上的差异可能是由于单位定义上不容易 被检测到的差异。例如，与已登记事件有关的可用信息、它们的时间描述、它们的法律定义可能在每个来源中都有所不同，这些方面的协调可能不会 没有错误，因此，将单位分配给我们的目标人群可能也不会没有错误。在 每个列表中，可能会由于注册/取消的延迟而出现错误。合并数据源时，识别单元时的错误可能导致重复或错误链接。

​	显然，任何一条可用的信息都应该包括在我们列表中的错误案例的识别过程中，并且，理想情况下，识别和删除虚假案例应该是我们的第一个阶段分析，之后可以对“干净的”数据使用一些捕获-再捕获技术。

​	然而，在许多情况下，现有的信息不足以挑出每一个错误的捕获，并且会有一定部分的不确定性，我们没有能力识别错误的原因。

​	对于这些情况，我们的方法包括将所有可能的(残余)错误定义为随机分类错误，并且我们提出了一种基于使用潜在类模型来估计它们的无监督方法。在这种情况下对分类错误的引用是很容易接受的，只要目标总体的归属是由辅助变量的值定义的。例如，如果将单位定义为一定年龄范围内的人，那么变量“年龄”的不确定性将完全体现在单位的分类中。然而，即使在这样的分类机制本身并不明显的情况下，这种对问题的看法也是有用的。

​	利用潜在变量来模拟一个单元的“真实”潜在状态，是行为科学和社 会科学的常见做法。在这些领域，潜变量通常代表一个不能直接观察到的 概念，只能通过相关指标来衡量。[4]中深入描述的另一个不同的概念是， 当观察到的(显化的)变量是所需变量的实际测量值，而代表其真实值的潜 变量是定义良好且可测量的，具有已知数量的模态。在这种情况下，我们 认为每个测量都可能受到误差的影响，信息的冗余使我们能够估计潜在变 量，并以无监督的方式评估每个测量源的准确性。这一概念应用的一个明 显例子是在多重诊断测试的潜在类模型中(概述见[38])，其中每个测试都有 假阳性和假阴性率，潜在变量识别真实的医疗状态。在我们的模型中，我 们引用后一种概念，其中二进制潜变量标识范围内和范围外的单位，而显 变量，即观察到的捕获，可以是假的也可以是真的，并且可以被解释为对 该潜变量的潜在错误测量。请注意，观察到的和潜在变量都是二进制的。 有一些捕获-再捕获模型的例子，对观察到的和潜在变量具有不同数量的模 态，即在多状态模型中(参见，例如，[27])，以解释状态分配中的不确定性。然而，我们将局限于二元情况。

​	在第8.2节中，我们用形式化的术语描述了模型，并给出了关于估计、可识别性和模型选择的几个细节。在第8.3节中，我们描述了使用协变量来模拟捕获概率的异质性，以及不可捕获的子种群的特定情况。在第8.4 节中，我们提供了一些关于使用我们在模型中提出的潜在类的可维持性的观察结果。在第8.5节中，我们提出了模型的贝叶斯方法。



### 8.2捕获-再捕获的潜在类模型

​	形式上，设k为列表的个数(或捕获场合)。设 $Yi$ 为随机变量，表示一个单元是否被第i个源捕获(即被列在第i个列表上):


 $$
Yi=\begin{cases} 1，如果单位在第i个列表中被捕获\\
0， 其他\end{cases}
$$

​	我们有一个k个变量的数组 $Yi=(Y1,...,Yk)$ 表示一个单元在k个不同列表中的捕获。每个单元观测到的二进制数组(在捕获-再捕获文献中通常称为捕获历史)记为 $y= (y1，…,yk)$ 。

​	设 $U$ 为任意列表所能捕获的所有单位的集合，即 $k$ 个源的目标总体的并集。设 $U1$ 为我们的目标总体。它必须是 $U1\subset U$ ，以便不存在任何无法捕捉的单位。我们可以用某些来源无法捕捉的单位来处理这种情况，但不是所有的(参见第 8.3.2节)。 $U$ 的基数， $|U|$ 记为 $N$ ，而 $|U1|=N1$ 。

​	观测到的单元可以在 $2k$ 列联表 $[n_y]y_{2k}∈{0,1}^k$ 中进行分类，其中 $n_y$ 表示具有捕获历史 $y$ 的单元数。观测到的单元总数为 ${\textstyle \sum_{y\ne0 }^{}}$n_y = n_obs$ ，而 $N=n_obs+n_0$ .

​	识别属于我们目标人群的单位的潜变量记为 
 $X=\begin{cases} 1，如果一个单位属于U1\\
 0，其他\end{cases}$ 
​	而 $n_{x,y}$ 表示存在捕获历史 $\underline{y}$ 的潜在类 $x$ 的单元数，因此 ${\textstyle\sum_{x\in 0,1}^{}}n_{x,y}=n_y$ ,而 $n_{0,\underline{0}}$ 是 $U$ 中但未捕获的单元数。

​	对于模型分布我们将使用[14]中引入的表示法，其中 $P(\underline{Y}=\underline{y})=\pi_y$ 。当随机变量从上下文看不清楚时，上标将最终表示是随机变量，因此 $\pi^{X,Y_k}_ {10}$ 表示概率 $P(X=1,Y_k)$ .我们考虑的模型类别可以表示为以下的混合模型：
 $\pi_{\underline{y}}=\sum_{x\in 0,1}^{}\pi_x\pi_{\underline{y}|x}$  

​	其中 $\pi_{\underline{y}|x}$ 是条件概率 $P(\underline{Y}=Y|x=x)$ ， $\pi_x$ 是属于潜在类 $x$ 的边际概率，即一个随机单位属于或不属于目标群体的概率，构成状态识别的不确定性估计混合模型的权重参数。因此，似然函数为：
 $$L(\pi_{\underline{y}};n_{\underline{y}})\propto\prod_{y}^{}\pi_{\underline{y}}^{n_\underline{y}}=\prod_{y}^{}(\sum_{x}^{} \pi_x\pi_{\underline{y}|x})^{n_{\underline{y}}}$$  

​	我们在这门课上可以考虑的最简单的模型：
 $$\pi_{\underline{y}}=\sum_{x\in0,1 }^{}\prod_{i=1}^{k}\pi_{y_i|x}$$  

​	满足局部独立假设，即显示变量在 $X$ 上是有条件独立的。这类模型在捕获-再捕获中对捕获概率中未观察到的异质性建模的应用是已知的(参见，例如[1])。然而请注意，局部独立假设在我们的设置中几乎是站不住脚的。正如我们已经说过的，我们正在考虑一个不受研究人员控制的捕获设置。因此，即使我们以潜在变量的值为条件，在不同列表中相同单元的捕获之间也可能存在正依赖性和负依赖性，因为在一个列表中记录的单元可能比未记录在该列表中的单元更有可能(或更少)出现在第二个列表中。

​	人们提出了各种方法来建模潜在类模型中的依赖关系，例如随机效应([28]，[8])，或多个潜在变量([10])。在贝叶斯上下文中，[23]以非参数的方式提出了一个先于模型依赖的狄利克雷过程。然而，可以追溯到[11]在捕获-再捕获中的经典方法是通过对数线性模型直接对这些依赖项建模;因此，为了探索显变量和潜在变量之间更复杂的依赖结构，我们将考虑一类具有潜在变量 $X$ 的分层对数线性模型，该模型与所有显变量相互作用。

​	已经证明(参见，例如，[15])模型(8.2)等效于对数线性模型： $[XY_1]...[XY_k]$ 

​其中我们使用经典的分层对数线性模型的符号，只报告高阶交互项(有时称为生成器)。模型(8.3)是我们将考虑的最简单的情况:相对于(8.3)的每一个额外的交互参数都代表了对局部独立假设的偏差。术语局部依赖模型(Local Dependence model)有时用于这种设置。关于这个模型用于捕获-再捕获的应用，请参见例如[5]和[31]。

​	我们的目标是估计目标种群 $N_1,i.e.$ ，即我们想估计  $X=1$ 的单位（包括捕获和未捕获）的数量。我们有 $N_1={\textstyle \sum_{y\ne 0}^{}n_{1,y}+n_{1,\underline{0}}}$ ,也就是说， $N1$ 等于每个捕获历史的范围内单元的数量之和，包括没有在任何列表中捕获的单元。



### 8.2.1可分解模型

​	在这里，我们介绍了模型的子类，称为可分解模型，这些模型将在以下内容中使用。在下一类中，我们首先介绍了依赖关系图。依赖关系图Gofajointcategoricaldis三分布是节点呈现变量的无向简单图，并且任何两个节点都是相邻的，除非相对变量是独立的（条件下是不稳定的）。我们可以将其图形化为依赖图形Gexhaustively定义了其联合分布的结构，即，如果联合分布不受G定义的拓扑的约束。注意，在图形化线性模型中，这相当于说，该模型完全包括了G集团提出的所有相互作用项，即G的延迟循环的产生者。阿莫德里被认为是可分解的，可以分解为依赖关系图。吉舒尔达尔，即，如果任何一个古罗马诺循环有一个单词（一个不是连接两个顶点的循环的一部分的数据）。如果阿莫德里是可分解，可以证明（[9]），联合分布因子是条件分布的乘积。

​	其中，设 $(C_1...C_g)$ 为关联图G的最大团， $({\textstyle\bigcup_{i=1}^{g}}C_i=G)$ ，则存在一个序 ${C_{\delta(1)},...,C_{\delta(g)}}$ 状态识别的不确定性估计，如果我们定义分隔符集 $S_2,...S_g$ 为：
 $$S_i=C_{\delta(i)}\cap\bigcup_{j=1}^{i-1}C_{\delta(j)}\qquad i=2,...,g$$


我们有这个

（1）每个分隔符 $S_i$ 为 $G$ 的团；

（2）每个 $S_i$ 包含在其中一个最大的团 $C_{\delta(j)}$ 和 $\delta(j)<i$ ；

（3）联合分布可以写成如下形式：

  $$\prod_{i=1}^{g}\pi^{C_i}(\prod_{j=2}^{g}\pi^{S_i})^{-1}$$ 


其中 $\pi$ 除以一个（子）图是作为（子）图中包含的变量的（边际）分布。

​	然后，如果我们将条件概率 $\pi^{X}$ 表示为 $\pi^{C_1|X}$ （稍微滥用了符号），我们可将可分解分布写成下面的乘积：
 
 $$\pi^{C_1}\prod_{i=2}^{g}\pi^{C_i|S_i}. $$

​	举例来说，请参考图8.1中 $Y=(A,B,C,D)$ 四个来源的图表。

​	我们只有两个具有该依赖关系图的分层对数线性模型：

 $$[AX][BX][CX][DX][CD]\qquad and\qquad [AX][BX][CDX].$$ 
 
只有第二种是图形化的，因为图形是和弦的，所以它是可分解的。实际上，我们有 $C_1$ ={ $A,X$ }, $C_2$ ={ $B,X$ }， $C_3$ ={ $C,D,X$ }, $S_2$ ={ $X$ }, $S_3$ ={ $X$ },模型可以写成：
 
 $$\pi_{\underline{y}}=\sum_{x}^{}\pi_x\pi_{a|x}\pi_{b|x}\pi_{cd|x} $$

可分解模型具有一些计算优势，正如我们将在本章的其余部分中看到的那样。

### 以下是王钦瑶的部分
#### 8.2.2 可识别性

我们所分析的这类模型具有可识别性的一个明显的必要条件是，独立参数的数量不大于观测到的不同剖面的数量 $\underline{y}$ - 1。因此，具有3个或更少明显二进制变量和结构零的潜在类模型本质上是不可识别的。事实上，在这种情况下，我们最多可以观察到7个不同的轮廓，而最简单的模型(8.3)将有7个参数。为了使用这样的模型，我们可以对参数施加一些限制，或者将一些协变量作为显式变量添加到模型中。

据我们所知，还没有发现这类模型可识别的一般充要条件。子类模型的结果可以在[32]和[2]中找到。然而，存在局部可识别的充要条件:Goodman[14]定义了一个模型，如果最大似然解在解周围的某个小区间(即 $\epsilon$ -邻域)内是唯一的，则该模型是局部可识别的。这比全局可识别性限制更少，在全局可识别性中，MLE必须在整个参数空间中惟一。Goodman证明了局部可识别性的充分必要条件是期望响应模式关于参数的雅可比矩阵是全列秩的。大多数用于潜在类别分析的计算机程序都包含对这种情况的检查。

#### 8.2.3 EM算法

为了计算我们模型的最大似然估计(MLE)，我们假设存在一个完整列联表 $T^{* }= \left[ n_{x,y}\right]$ ，我们观察了其中的边际计数 $T$ 。我们定义一个带有参数 { $\lambda$ } 的 $T^ {* }$ 的对数线性模型，然后，一旦我们初始化了参数{ $\lambda$ }的估计(或者， $T^ {* }$ 的单元格)，我们就可以设置一个EM算法，迭代如下两步:

E-step:计算 $T^ {* }$ 条件下在观测边缘 $T$ 上的细胞的期望计数和{ $\lambda$ }的当前估计，对于每个轮廓 $y$ ，计算估计的后验概率 $\widehat{\pi}_ {x|\underline{y}}$ 和

 $$ \widehat{n}_ {x\underline{y}}=n_{\underline{y}}\widehat{\pi}_ {x|\underline{y}}$$

M-step：更新对数线性模型参数{ $\lambda$ }在E-step中计算的频率 $\widehat{n}_ {x\underline{y}}$ 上的MLE。

在M-step中，可以使用迭代比例拟合(IPF)算法(algorithm)来获得{ $\lambda$ }的最大似得。实际上，已经证明IPF不需要完全收敛:在每个M-step上进行一次迭代就足以使整个EM算法收敛(参见，例[30])。

理论上可以采用两种方法进行估计过程:条件估计和无条件估计(见[11])。在条件方法中，我们将在结构零单元上有条件地最大化对数似然，这将从算法的两个步骤中排除。一旦EM算法收敛，{ $\lambda$ }的当前的MLE被用来估计 $T^ {* }$ 的每个单元，包括结构零单元 $n_{x,\underline{0}}$ 。另一方面，无条件方法相当于在每次迭代中估计和更新结构零单元 $n_{\underline{0}}$ 。为此，我们应该使用一个“嵌套”EM算法(见[6])，它有两个嵌套周期，其中外层周期初始化并更新结构零单元格 $\widehat{n}_ {\underline{0}}$ 的估计，而内部周期则根据当前 $T \cup \widehat{n}_ {\underline{0}}$ 更新完整数据 $T^ {* }$ 。(包括单元格 $\widehat{n}_ {x,\underline{0}}$ )的估计。然而，由于这两种方法是等效的，第一种方法更可取，因为它在计算上更容易。

当模型可分解时，我们可以避免对数线性表达式，并且算法的M-step可以以封闭形式求解，因为我们有一个参数最大化完全对数似然的解析公式。也就是说，由于完全对数似然可以表示为

$$ \pi _ {x,y}= \pi _ {C_{1}}\prod _ {i=2}^{g}\pi _ {C_{i}|S_{i}}$$

我们可以用 $\widehat { n }_ {C _ { i }} / \widehat { n }_ {S _ { i }}$ 估计每个参数 $\pi _ {C_{i}|S_{i}}$  ，其中 $\widehat { n }_ {C _ { i }}$ 和 $\widehat { n }_ {S _ { i }}$ 是通过将步骤E得到的 $\widehat{n}_ {x\underline{y}}$ 除以两个子图中不包括的变量来得到的。

例如，在估计模型(8.6)中，M-step可以计算出:

 $\widehat{\pi}_ {x}= \frac{\widehat{n}_ {x}}{n_{obs}}$  ，  $\widehat{\pi}_ {a|x}= \frac{\widehat{n}_ {xa}}{\widehat{n}_ {x}}$ ， $\widehat{\pi}_ {b|x}= \frac{\widehat{n}_ {xb}}{\widehat{n}_ {x}}$ ， $\widehat{\pi}_ {cd|x}= \frac{\widehat{n}_ {xcd}}{\widehat{n}_ {x}}$ 。

其中

$\widehat{n}_ {x}= \sum _ {\underline{y} \neq \underline{0}}\widehat{n}_ {x\underline{y}}$ ， $\widehat{n}_ {xa}= \sum _ {b,c,d}\widehat{n}_ {xabcd}$ ， $\widehat{n}_ {xb}= \sum _ {a,c,d}\widehat{n}_ {xabcd}$ ， $\widehat{n}_ {xcd}= \sum _ {a,b}\widehat{n}_ {xabcd}$ 。

#### 8.2.4 固定的参数

我们采用的潜在类模型的无监督方法暗示了对每个来源的质量(即错误率的评估)的中立观点。由于这个原因，当没有可用的审计样本时，潜在类别模型有时被用来估计一组源中的错误率。但是，如果我们有一些关于信息源错误率的可靠信息，我们可以通过固定一些参数将其包含在模型中。例如，如果我们知道源 $Y$ 没有错误捕获，我们可以将相应的参数 $\pi _ {1|0}^{Y|X}$ 固定为零。

对参数施加一些限制的另一个原因是，通过假设一个更节俭的模型来节省大量的自由。在某些情况下，为了有一个可识别的模型，这是必要的。也就是说，也就是说，当可用列表的数量不允许使用更复杂的模型时。

只要我们考虑可分解模型，并且我们想施加的限制类型是将参数固定为特定值或在参数之间施加相等约束，我们就可以通过一个相当简单的过程最大化受约束的似然。Goodman在1974年提出了一个在大多数情况下都有效的简单方法。Mooijaart和van der Heijden[24]随后改进了Goodman的算法，并提出通过在对数似然函数中添加拉格朗日乘子来估计概率具有相等和/或固定值限制的(可分解)模型。

#### 8.2.5 不同成分的混合物

我们想指出我们正在考虑的对数线性模型的一个假设，它限制了我们可以表示的关系:即两个分量分布(以 $X=1$ 和 $X = 0$ 为条件)具有相同的依赖结构。在某些情况下，这一点是不合适的。

例如，在模型 $[AX]$ $[BX]$ 下，无论 $X$ 等于 $1$ 还是 $0$ , $A$ 和 $B$ 都是有条件独立的。如果我们添加项 $[AB]$ ，我们将允许 $A$ 和 $B$ 有条件地依赖于 $X$ ，但无论 $X = 1$ 还是 $X = 0$ ，相互作用的参数 $[AB]$ 都是相同的。如果我们也添加项 $[ABX]$ ，那么 $A$ 和 $B$ 之间的相互作用在 $X = 1$ 和 $X = 0$ 上不一定是有条件地相同的，但这种包括高阶相互作用的策略可能会导致过度参数化。不难想象这样一种情况， $A$ 和 $B$ 在一个子种群中是独立的，所以，比如说，

$\pi _ {ab|0}= \pi _ {a|0}\pi _ {b|0}$ ，但 $\pi _ {ab|1}\neq \pi _ {a|1}\pi _ {b|1}$ 。

例如，假设我们有两个具有相同问题的来源，识别二进制状态。假设“ $0$ ”状态与应答者无关，而“ $1$ ”表示可能被隐藏的敏感状态。在这种情况下，条件独立假设在 $X = 0$ 时成立，但当 $X = 1$ 时，被调查者在两次调查中的说谎倾向是一致的。

在这种情况下，我们想在模型 $[ABX]$ 中固定约束 $\pi _ {ab|0}= \pi _ {a|0}\pi _ {b|0}$ ，但这不是估计算法中容易处理的约束(见8.2.4节)。一种可能的解决方法是放弃对数线性形式，并定义两个不相等分量分布的混合模型:

$$ \pi _ {ab}= \pi _ {0}\pi _ {a|0}\pi _ {b|0}+ \pi _ {1}\pi _ {ab|1}$$

通过这种方式，两个组件可以独立定义(最终为两个不同的对数线性模型)。这种泛化对估计过程没有任何困难。事实上，在算法的步骤M中，我们可以分别处理与步骤E中估计的值 $\widehat{n}_ {1,\underline{y}}$ 有关的完全对数似然值的部分和与值 $\widehat{n}_ {0,\underline{y}}$ 有关的部分。

这类模型的使用例子可以在记录链接的混合模型中找到，其中[18]提出了一个模型，其中相对于真匹配的对数线性组件仅具有主效应，而第二个组件具有所有主效应和双向交互。也就是说，该模型在 $X = 1$ 时满足条件独立假设。其思想是，如果我们有一个真正的匹配，在各种显式变量上的分歧是随机错误的结果，而在不匹配的情况下，分歧更有可能发生在逻辑集中([42])。

#### 8.2.6 模型选择

模型选择是捕获-再捕获中的一个关键点，因为通常对总体规模的估计对参数选择的微小变化非常敏感。解决这个问题的典型方法是使用信息标准来比较模型。特别是，可以使用逐步的(向后或向前)过程来进行基于AIC或BIC的参数选择。然而，我们在专门为潜在类模型设计的文献中有几个结果。这方面的大部分贡献都集中在使用局部独立模型(8.2)时检测清单变量之间的成对依赖关系。第一种方法是比较任意一对源 $Y^{\prime}$ 和 $Y^{\prime \prime}$ 的估计和观测二元边缘 $\pi ^{Y^{\prime}Y^{\prime \prime}}$ 和 $\widehat{\pi} ^{Y^{\prime}Y^{\prime \prime}}$ 。

Qu等人[28]建议检验估计的相关性

$$\widehat{Corr}_ {Y ^ { \prime } Y ^ { \prime \prime }} = \frac { \widehat{\pi} _ {11} ^{Y^{\prime}Y^{\prime\prime}}-\widehat{\pi}_ {1}^{Y^{\prime}}\widehat{\pi}_ {1}^{Y^{\prime\prime}} } { \sqrt { \widehat{\pi}_ {1}^{Y^{\prime}} ( 1 - \widehat{\pi}_ {1}^{Y^{\prime}}) \widehat{\pi}_ {1}^{Y^{\prime\prime}} ( 1 - \widehat{\pi}_ {1}^{Y^{\prime\prime}} )  }}$$

和观察到的，并计算每对变量的差值。最终使用自举置信区间可以发现显著差异，相应的成对交互项可以添加到对数线性模型中。

二元残差(BVR)计算两个二元分布之间的卡方距离:

$$\sum _ { i , j \in  { [0 , 1] } ^ { 2 } } \frac { ( n _ {i,j}^{Y^{\prime}Y^{\prime\prime}}- \widehat{n} _ {i,j}^{Y^{\prime}Y^{\prime\prime}})^2 } {  \widehat{n} _ {i,j}^{Y^{\prime}Y^{\prime\prime}} }$$

显然(见[25])BVR指数不具有[40]中所述的渐近 $\chi^2$ 分布。然后，可以再次使用自举置信区间。

另一个近年来受到关注的统计数据是预期参数变化(EPC)，被称为结构方程建模中的修改指数，它允许人们检测模型中不包含的参数更相关([25]，[26])。我们考虑一个由参数 $\theta_0$ 定义的空模型，和一个由参数 $θ = (θ_0，θ_1)$ 定义的替代模型。空模型被视为参数 $θ_1$ 被限制为等于零的模型。如果它们被释放，然后EPC估计参数 $θ_1$ 的位移。设 $\underline{s}θ_1$ 为固定参数的积分向量，$\underline{s}θ_1 =∂l(θ)/∂θ_1$ ，设 $\widehat{I}(θ)$ 为期望的信息矩阵。然后，如果空模型成立，则测试统计量

$$\underline{s}_ {\theta _ {1}}^{T}\widehat{I}(\theta)^{-1}\underline{s}_ {\theta _ {1}}$$，

在 $θ_1 = 0$ 处的值渐近地分布为 $χ^2$ ，其自由度等于 $θ_1$ 中参数的数量。

话虽如此，上述任何工具选择的最佳模型并不总是给出最佳 $N_1$ 估计的模型，而且可能是具有相似拟合优度水平的不同模型导致对总体规模的估计非常不同。

然后，在模型评估中纳入一些关于主题的考虑是很重要的。参数的估计应该基于我们对数据的先验知识进行评估，某些参数值不合理的模型应该被丢弃。

注意，第8.2.3节算法得到的参数是指结构零单元上有条件截断的分布。因此，为了对参数有一个清晰的解释，我们首先必须估计完全列联表 $T^{* }$ ，并推导出完全分布的参数。

# 以下内容为万亚珂完成：
# 8.3 观察到的捕获概率的异质性

## 8.3.1 协变量的使用

即使我们对列表之间的所有现有依赖关系进行建模，也可能存在仍会有一些无法解释的变化，这是因为个人被捕获的倾向性。一些捕获概率的异质性可以由一组协变量来解释，这些协变量必须包括在模型中。

如果未能对个体捕获概率中的列表依赖性或异质性进行建模，通常会导致对种群大小的有偏估计。然而请注意，这两个方面是不容易分开的。一个具有足够数量参数y的对数线性模型可以代表 $$ \left\{ 0,1 \right\} ^{k}$$ 上的任何分布；因此，原则上总是有可能找到具有任何拟合优度水平的（可能是过度参数化的）模型。如果在模型中不包含个体异质性的相关来源，就会导致列表之间的虚假依赖关系，并且可能会错误地包含在模型中的虚假参数。

单个协变量的使用通常包括在模型中的两种方式之一（关于对数线性模型中两种方法的分析，见[37])。第一种方法是使用观察到的协变量来影响模型参数。也就是说，我们重新参数化潜伏类成员的概率（混合权重$$\pi _ { x }$$)和/或条件捕获概率$$ \pi _{y|x}$$，以一组协变量为基础。在这种方法中，协变量明确地具有解释变量的作用；它们既可以是分类的，也可以是连续的，而且有可能限制它们对特定参数的影响。通过将对数线性模型的公式转化为多项logit模型，可以通过几种方式实现参数化模型（见[39]、[43]、[35]、[36]）。

第二种方法，只有在所有协变量都是分类的时才可用，将它们作为清单变量。也就是说，我们为联合分布$$ \pi _{y,v}$$定义了一个模型，其中V是我们的协变量集。通过这种方式，我们可以对所有清单变量（捕获或协变量）之间的关系进行建模，并通过几种方式调整它们的依赖图。

必须指出的是在这种方法中，协变量并不一定存在影响$$N{1}$$的估计，除非它与其他证明的依赖关系变量是经过精心选择的。估计的不变性与对数线性模型的坍陷性有关。假设我们在一组变量Y上有一个对数线性模型M，我们考虑变量Y‘的一个子集，以及相对诱导对数线性模型M’，它只保持M相对于Y’中的所有变量的参数。如果模型M‘对每个单元格$$n{y^{\prime}}$$的估计等于模型M所对应的边际估计，则称M在Y’以上是可折叠的。设G为M的依赖图，H为Y/Y ’上的诱导子图，即未包含在Y‘中的G的变量图。Asmussen和Edwards [3]找到了可折叠的充分必要条件，即如果H的每个连通分量的G边界在M在Y‘上是可折叠的，构成M’的生成器。那么，如果$$ \pi _{x,y,v}$$的对数线性模型可在（X，Y）上折叠，那么协变量不会改变$$N{1}$$的估计。关于这方面，也可以看本书的第七章。

举个例子，假设我们想在图8.1的模型中包含协变量V。然后,建立模型

$$ \left[ AX \right] \left[ BX \right] \left[ CDX \right] \left[ CDV\right]$$

在{A、B、C、D、X}上是可折叠的，因为C和D在图中是连通的，而V不会改变$$N{1}$$的最终估计。相反，模型

$$ \left[ AX \right] \left[ BX \right] \left[ CDX \right] \left[ AV \right] \left[ CV\right]$$

是不可折叠的，因为A和C不连接，而V会影响$$N{1}$$的估计。

然而，请注意，这只对观察到的变量有效：如果V与潜在的X相互作用，那么它通常不会是可折叠的。例如，模型

$$ \left[ AVX \right] \left[ BX \right] \left[ CDX \right] ,$$

其中列表A的过覆盖误差随V变化，即使{A,X}是图的一个派系，在{A、B、C、D、X}上不可折叠。

值得注意的是，如果我们对估计由协变量确定的每个地层的种群大小感兴趣，那么即使是一个可折叠的模型也可能是有用的，因为我们可以简单地估计所有值v的数量$$n \frac{Y_{}}{0}\frac{V}{v}$$。

## 8.3.2 不完整的列表

捕获概率的异质性的一个极端情况是由不可捕获的亚种群来表示的，即被捕获的概率为零的单位。在这里，我们处理已确定的亚种群的情况，即已知的一个或多个列表（但不是全部）无法接受的单位。这个问题在实践中经常发生，因为当一个源针对我们感兴趣的人群的一个子集时，它就会发生。我们不想丢失那些我们将称之为“不完整来源”中可用的信息；然而，我们需要考虑它们在模型中的不完整性。也就是说，如果我们忽略列表的结构不完全性，并将不可捕获的单位视为抽样零，那么对种群规模的结果估计可能会有严重的偏差。

我们假设我们对每个不完整的列表都无法捕获的亚种群（或地层）有一个完美的知识。因此，U被划分为不同的不完整列表不运行的层。这可以通过分层变量S形式化划分U。由于S是已知的，我们可以采用一种简单的方法，用不同的模型分别估计每个地层的亚种群的大小。每个模型将只包括相对地层上的列表，然后将估计数相加将得出总人口规模估计数。然而，这种方法将极大地限制我们可以考虑的可识别模型的范围，因为我们经常遇到以下情况：不完整的列表有单独的目标，只有一个小子集，所有列表操作。例如，考虑4个列表和2个层的简单情况，一个是所有列表操作，另一个是只有3个列表操作。在第二层中，我们可以只考虑几个简单的对数线性模型，而一个潜在的类模型是不可识别的。

另一种方法是将未被不完整列表所覆盖的单元的不可观察捕获视为缺失信息。然后，将这些地层中的单元视为部分分类，即好像捕获历史部分缺失，然后我们估计缺失的部分。当然，潜在的假设是，在其他列表的条件下，每个不完整列表在地层中的分布是相同的，也就是说，我们假设一个随机缺失（MAR）机制(见[19]，章.3.2见[39])。如果这个假设是站得住脚的，我们可以在一个模型中包含所有记录，即使存在不完整的列表。另一方面，当假设不正确时，所得到的估计可能会有偏差。

使用对数线性模型来推断列联表中的部分缺失信息是众所周知的（见[30]）。这种方法在捕获中的应用，在[44]中也进行了探索。扩展到存在潜在变量的情况并没有任何困难，因为它不需要对第8.2.3节中描述的算法进行很少的修改。但是，请注意，这两个方面（潜在变量X和不完整的列表）不能很容易地用对数线性模型单独来解决。事实上，由于X与所有明显的变量相互作用，因此（X、Y、S）的对数线性模型将不能折叠到（Y、S）上。因此，如果有人想初步处理由于不完整的列表而造成的缺失，然后在完整的数据上估计潜在的类模型，他们应该定义和估计两个不同的对数线性模型。

假设分层变量S在一个有限的集合S = {s1，s2，...}中取值，以识别不同的不完整列表集合不工作的不同地层。对于每个地层s，我们观察到一组不同的边际计数$$T_{s}$$。我们假设存在一个完整的列联表$$T^{}= \left[ n{x,y,s}\right] ,$$，并且我们想要估计

$$N _ { 1 } = \sum _ { y \in\{ 0 , 1 \} ^ { k }{s\in S} } n _ { 1,y, s }$$

然后，在EM算法的E步中，对于每个层s，我们根据观察到的计数$$T _ { s } .$$有条件地计算$$T ^ { * }$$相应细胞的期望计数$$ \widehat{n}_{x,y,s}$$。

应注意$$T ^ { * }$$模型的依赖结构的选择。事实上，在许多情况下，S，或一些模式，可以构成一个有用的协变量来解释一些异质性捕获概率，我们想包括一些交互参数与其他变量，以这样一种方式模型不能折叠（X，Y）。然而，当且仅当处于某一地层的概率独立于所有不在该地层中运行的列表时，不完整列表的MAR假设才成立。因此，一个S与不完整的列表变量相互作用的模型将违反MAR假设，如果没有进一步的假设，它将无法被识别。相反，一个S不与任何其他变量相互作用的模型意味着缺失机制是完全随机的（MCAR）。

在存在不完整列表的情况下，我们有多个结构零单元格需要估计。它们的数量在每一层中的变化取决于不完整的列表的数量。形式上，设S=表示Y1，...，Ym，m < k不运行的地层。然后，对于该层，我们有以下$$2^{m+1}$$结构零细胞：

$$\{ n\begin{array}  { l  }  { X , Y _ { 1 } , \cdots , Y _ { m },  \cdots,Y _ { m } + 1 ,  Y _ { k  } , S } \\ { x,y _ { 1 }, \cdots,y_{m},0, \cdots,0,s } \end{array} _ { ( x , y_{1},\cdots,y_{m} \in \left\{ 0,1 \right\} ^{m+1}) }$$

在EM算法中排除，并在其收敛后进行估计。

例如，考虑列表A、B、C和D，其中列表A不完整，而S∈{s1，s2}表示A是否可操作。观察到的边际计数为$$T _ { 1 } = [ n _ { a b c d s _ { 1 } } ]$$和$$T _ { 1 } = [ n _ { b c d s_ { 2 } } ]$$。$$T ^ { * }$$的结构性零细胞为：

$$n{x0000s{1}}^{XABC}$$ , $$n_{x0000s_{2}}^{XABCDS}$$ ,and $$n_{x1000s_{2}}^{XABCDS}$$ , $$forx \in \left\{ 0,1\right\}$$

观测到的不完整数据的对数似然值为：

$$ \sum _{a,b,c,d}n_{abcds_{1}}\log \pi _{abcds_{1}}+ \sum _{b,c,d}n_{bcds_{2}}\log \pi _{bcds_{2}}$$

而EM算法的指定方式如下：

1. 随机初始化条件概率{$$ \widehat{\pi}_{x|abcds_{1}}$$}和{$$ \widehat{\pi}_{x|abcds_{2}}$$}；

2. 通过计算估计完整的列联表$$ \widehat{T}^{*}= \left[ n_{xabcds}\right]$$，排除结构零单元格（8.7）

$$\widehat{n}_{xabcds_{1}}=n_{abcds_{1}}\widehat{\pi}_{x|abcds_{1}}$$  $$ \forall cells s.t.(a,b,c,d)\neq(0,0,0,0)$$

$$\widehat{n}_{xabcds_{2}}=n_{abcds_{1}}\widehat{\pi}_{x|abcds_{2}}$$  $$ \forall cells s.t.(a,b,c,d)\neq(0,0,0,0)$$

3. 根据不可观测的结构零单元（8.7），计算当前$$ \widehat{T}^{*}$$上所选择的对数线性模型的MLE；

4. 更新条件概率的当前估计值

$$ \widehat{\pi}_{x|s_{1}abcd}$$=$$\frac{\widehat{n}_{xa_{n}abds_{1}}}{ \sum _{a,b,c,d}\widehat{n}_{xabcds_{1}}},$$，

$$ \widehat{\pi}_{x|s_{2}abcd}$$=$$\frac{\widehat{n}_{xa_{n}abds_{2}}}{ \sum _{a,b,c,d}\widehat{n}_{xabcds_{2}}},$$，



5.重复2-4次，直到收敛。

在收敛后，我们估计了单元格（8.7）。

请注意，在我们正在考虑的一些模型中，可以对不完整的列表（或一般缺失的数据）采用一种更简单的方法。事实上，如果模型是可分解的，并且缺失的部分和观察到的部分形成了不同的似然因素，我们可以采用所谓的“全信息最大似然”方法。在这种情况下，一个单位的值只是意味着可能性中没有相对参数。例如，如果B是模型中的一个不完整的列表（或在任何情况下都是一个有缺失值的列表）
$$\pi _ { A b c d s } = \sum _ {x \in \ left \{ 0,1\ right \}} \pi _ { x } \pi _ { a | x } \pi _ { b | x } \pi _ { c d | x } \pi _ { s }$$

然后，所有有B缺失值的单位，根据数量对可能性的贡献

$$ \sum _{x}\pi _{x}\pi _{a|x}\pi _{cd|x},$$

不需要进一步的计算工作。在局部独立模型（8.2）下，任何缺失值的模式都可以用这种方式来处理

不幸的是，并不是所有缺失的模式都可以按照这段中的描述来处理。事实上，我们需要一个所有列表同时运行的子种群，以便能够估计一个潜在的类模型。原因依赖于这样一个事实，即即使在模型（8.3）的最简单的情况下，最小的充分统计量是观察到的计数 $$n{y}$$ ，我们不能通过充分性实现数据缩减（见[12]）。因此，如果在我们的数据中，我们不能观察到 ${n_y}$ ，而只是一些边际计数，我们的估计可能是有偏差的。在没有观察到高阶联合分布的情况下（即，在对数线性术语中，不能估计高阶的相互作用），这些项的影响很低，并且估计 $N{1}$ 的最终偏差可以忽略不计。

# 8.4评估对潜在类别的解释

我们的模型背后的基本思想本质上是隐藏在概率记录链接问题背后的相同思想，其中二进制潜在变量旨在识别真匹配和假匹配。也就是说，在我们的模型中，我们隐式地假设有两个具有不同分布的子种群代表所期望的情况和虚假的情况，并且两个分布的混合将代表我们的数据。

当然，这种对潜在变量的解释是可以进行验证的。事实上，有限混合模型在捕获-再捕获中的常用用法是对个体间未观察到的捕获概率的异质性进行建模，这在包含可用的协变量后仍无法解释。其基本原理是通过建模观察不能直接识别的不同亚种群数据来增强拟合。通常，组件的数量的选择是一个在拟合优度和参数数量的简约性之间的平衡的问题。因此，两个潜在组件的混合不一定代表我们期望的感兴趣的子种群（范围内和范围外单元）。例如，如果我们有两组明显不同的单位，它们具有非常不同的捕获概率和相似的错误捕获率，那么一个两类模型很可能会识别这两组，而不是错误捕获和真实捕获。

当然，我们对潜在变量的解释的合理性可以通过后验来检验。事实上，除非模型被严重错误指定，否则估计的概率$$ \widehat{\pi}_{y|x}$$和估计的后验概率$$ \widehat{\pi}_{x|y}$$将有助于我们解释潜在变量，识别潜在类别的类别性质，并理解我们所做的假设是否成立。

我们对这个问题的先验知识应该指导我们评估这些可能性的合理性。例如，在许多感兴趣的情况下，我们期望几乎所有源的假捕获率都很低，以及它们之间的积极相互作用。如果明显变量都与X高度相关，并且潜在类被很好地分离出来，也就是说，如果类$$ \widehat{\pi}{y|x}$$的概率接近于0或1，那么这就构成了支持我们的论点的证据。特别是，我们期望 $$ \widehat{\pi}{1|1}$$ 和 $$ \widehat{\pi}{0|0}$$ 的概率接近于1。相反，如果所有源在两个潜在类中捕获概率都超过0.5，而$$ \widehat{\pi}{1|1}$$和$$ \widehat{\pi}_{0|0}$$远非一个，这将将潜在类解释为具有不同被捕获倾向的两个亚种群。

请注意，所有有限的混合模型最多都是可识别的，直到潜在类的标签的任意排列（标签切换问题）。因此，总是需要通过分析估计的参数来识别代表真实捕获的潜在类，即使模型的可拉性不是一个问题。


# 以下部分为王若琳同学的作业：

​      &emsp;我们顺便注意到每个清单变量与X的相关性，可以用一个简单的形式来表示覆盖不足和覆盖过多的比率：

$$\left. \begin{array} {l}{Cov[Y,X]=\pi _ {11}^{Y|X} - \pi _ {1}^{X}\pi _ {1}^ {Y}\\ {= \pi _ {1}^{X} \pi _ {0}^{X} (1 - \pi _ {0|1}^{ Y | X }- \pi_  {1|0} ^ {Y|X} } ) } \end{array} \right.$$ 

​        &emsp;因此，如果源Y的覆盖率不足率和覆盖率过高率的总和接近于1，那么Y通常会与X弱相关，并且它对模型的贡献会很差。如果错误率之和超过1，则相关性将是负的，并且Y的作用可能混杂在潜在变量的识别和解释中。因此，如果我们知道一个源的质量很差，有很高的错误率，在某些情况下，从模型中排除它可能是最好的选择。

​        &emsp;可以涵盖这两个方面(捕获中未观察到的异构性概率和真/假捕获)在同一模型中使用多个潜在变量或多个潜在类。在潜在类别模型中使用多个潜在变量早在[14]中就有暗示(另见[16]，[4])。包含两个(或更多)潜在变量允许我们指定更复杂的变量依赖结构在我们的模型和调整在一个更精细的交互道路。然而，人们应该识别潜在变量，它们各自的模态的数量，以及它们在图g中的依赖性。所以，除非我们有一个附加潜在变量所反映的主题的特定知识一个关于产生数据机制的具体假设，一个更简单的解决方案是否考虑一个潜在变量与许多潜在类别更大超过两个。这样一来，我们就必须选择最好数量的类，然后通过标记它们代表真捕获或假捕获，将潜在类别分为两组。设g为所选的潜数类 $x_1,\cdots,x_g$ ,设 $w_1$ 和 $w_2$ 是表示true的类集合和假案例。然后，属于后验概率剖面为 $\vec{y}$ 的单位的目标人口数为:

$$ \frac{\sum_{i\in W _{1}}\pi_{x_{i},y}}{\sum_{i=1}^g\pi_{x_{i},y}} $$ 

​       &emsp; 这两种方法的应用示例请参见[10]中的医学诊断测试，[18]为一个记录联动。

# 8.5 贝叶斯方法

​        &emsp;在本节中，我们将介绍我们的模型的贝叶斯方法。我们将只关注可分解模型，因为这些模型的贝叶斯方法很简单，而一般情况下会出现一些计算困难。

​        &emsp;贝叶斯方法的一个明显优势是可以以一种简单的方式包含手头数据的先验知识。我们可以在对参数值的信念建模之前设置一个信息，而不是像8.2.4节中所见的那样固定它，我们可以平滑地调整我们的置信度。此外，信息先验可以帮助我们确定所需的潜在亚群体。

​        &emsp;在贝叶斯方法中，我们可以很容易地计算群体大小的区间估计，这在捕获中一直很难于重新研究。在非贝叶斯背景中，我们被限制于自举方法，这是计算密集型的，因为潜在变量是的。两个数学家[31]扩展了[7]的结果，提出了一种基于对数线性模型中使用剖面对数似然的方法来有条件地估计少计数的置信区间协变量的值。然而，他们的方法不能轻易地扩展到计算总少计的置信区间。相反，在贝叶斯方法中，当我们检查其后验分布时，自然地获得了总体大小的区间估计。

​        &emsp;另一个有利的观点是，可以使用多种工具进行解释模型的不确定性。特别地，我们在模型平均中得到了一些结果以及专门为可分解对数线性模型设计的模型选择(见[20]，[21])。

​         &emsp;对于可分解模型的先验分布，我们有两个建议。第一个是一类先验，称为超狄利克雷它是共轭的模型(8.4)，具有在边缘化下封闭的性质(见[9])。对于每一个极大团 $\mathcal C$ ,称为 $\mathcal h$ 变量 ；对于每一个分布 $Π^c$ ,设置一个有参数的(h−1)维单形设狄利克雷函数 $\alpha_{y_c}$ 为每个可能的值组合定义 $\vec{y_c}\in\lbrace{0,1}\rbrace^h$ 在极大团 $\mathcal C$ 中。这些先验不是独立的，因此，为了保证任何交点的边缘分布是一致的，我们对参数施加如下限制:
 
 $$ \sum\alpha_{y_{C_{i-1}}}=\alpha_{S_{{i}}}=\sum\alpha_{y_{c_ {i}}}\quad i = 2 ,\cdots,g, $$
 
​         &emsp;其目的在于对变量 $\vec{y_{S_{i}}}$ 进行一致的组合。这类先验的应用可以在[21]中找到。   

​        &emsp;在第二种方法中，我们引用表达式(8.5)。对于每一个 $Π^{C_i|S_i}$ 和每一个 $S_i$ 的固定值，我们设置一个狄利克雷分布限制。这些分布是相互独立的，就像 $Π^{C_i|S_i}$ 独立于结构之中，不难看出这类先验与(8.5)共轭。这种方法被用于局部独立下潜在类模型的贝叶斯分析(8.2)。(见[41])

​        &emsp;示例如下，思考模型 ${[ABX][CDX]}$ , $C_1 = \{A,B,X\},C_2=\{C,D,X\},S_2=\{X\}$ 第一种方法将设置两个Dirichlet分布:

$$\pi ^{ABX}\sim Dir (\alpha _ {abx}^{ABX}) \quad  \quad \pi^{CDX}\sim  (\alpha _ {cdx}^{CDX})$$

 &emsp;限制如下: $\alpha_{x}=\sum _ {a,b} \alpha _ {abx} = \sum _ {c,d} \alpha _ {cdx}$ ，
 
 &emsp;目的是为了确保 $Π^X$ 会 在这两种情况中保持一致。从 $\sum _ {a,b} n _ {abx} = \sum _ {c,d} n _ {cdx}$ 尾部的公式会一直持续。

​        &emsp;在第二种方法中，我们将设置四个狄利克雷分布:

$$\pi ^ {AB|X} \sim Dir (\alpha _ {ab|x} ) (x = 0,1) , \quad \pi ^ {CD|X} \sim Dir (\alpha_ {cd|x } ^ {CD|X}  ) (x = 0 ,1)$$

和一个Beta分布：

$$\pi^{X} \sim Beta( \alpha _ {0}^{X} , \alpha _ {1}^{X} )$$ 

​        &emsp;Dirichlet的非信息先验可以设置所有参数(参数)为1/2(遵循多项抽样的Jeffreys先验)，或为1(遵循均匀分布)。相反，如果我们想包含一些先验知识，我们可以将狄利克雷参数的通常解释作为“伪计数”添加到实际计数 $n_{\vec{y}}$ 中。例如，如果我们认为源Y几乎没有过度覆盖，我们会设置 $\alpha_{0|0}^{Y|X}$ 比 $\alpha _ {1|0}^{Y|X}$ 大.
​        &emsp;仍然需要在 $n_ {\vec{0}}$ 上设置先验分布，或者等价地，在N上设置先验分布。以下是文献中关于贝叶斯捕获-再捕获的常见选项:

•不恰当的平坦先验:P (N)∝1/N;
•泊松分布，最终与其pa参数上的超先验:N∼Poi (λ)， λ∼Gamma(α， β);
•里萨宁分布([29])，它总是恰当的，由p (N)∝2−log∗(N)给出，其中log∗(N)是数列{ $\log_2(N)，log_2(log_2(N))$ ，…}中正数项的和。

​        &emsp;我们进一步假设N和 $\theta$  的先验分布是相互独立的。

## 8.5.1 蒙特卡洛算法

​        &emsp;在本节中，我们详细介绍了基于Gibbs的蒙洛卡特算法从 $N_1$ 的后验分布进行抽样的步骤。让我们将模型的参数表示为 $\theta$ ，无论它们是否为 $\{Π^{C_i|S_i}\}$ 或 $\{Π^{C_i}\}$ 然后，在迭代(t+1)时，

1、狄利克雷分布从后验条件分布中对所有参数Θ(t+1)进行抽样；

2、

$$P (N|\theta,T)=P(N|\theta,n _ {0,bs)} = \frac {P (N)} {P(n_{0bs|\theta})} P(n_ {obs}|N,\theta)\propto  P(N)\dbinom{N}{n_{obs}} \pi _{\vec{0}}^{N-n_{0bs}}(1-\pi_{\vec{0}})^n_{obs}$$ 

​         &emsp;如果我们选择非正常先验 $P(N)\propto 1/N$ ,会得到 $N^{(t+1)} \sim \operatorname {NegBin} (n_{0bs},1-\pi _ {\vec{0}}^{(t + 1)})$ 
3、
$$N_{x,\vec{y}}^{(t + 1)} \sim Bin (n_{\vec{y}},\pi _{x|\vec{y}}^{(t+1)}\qquad n_{\vec{0}}) = N^{(t + 1)}-n _ {0bs}$$

 &emsp; 如果我们参考模型 $\{[ABX][CDX}$ 的例子，并参考参数化(8.5)，第一步包括以下三个步骤:

1、从后验的 $P (\pi^{X}|N_{x,y})$ 得到的样本 $\pi _ {x}^{(t + 1)}$ ，是Beta分布 $\operatorname {Beta} (n _ {x}^{(t)}+\alpha _ {x}) \qquad n_{x}^{(t)}=\sum _ { \vec{y}}^{n} x_{\vec{y}}$ ；

2、从 $P(\pi^{AB|X}|N _ {x,\vec{y}})$ 中得到的样本 $\pi^{(t + 1)}$ ，是狄利克雷分布 $Dir(n_{abx}^{(t)} + \alpha _ {ab|x}) \qquad n_{abx} ^ {(t)} = \sum _ {\vec{y}:(A=a,B=b)}n_{x,\vec{y}}$ ；

3、从 $P (\pi^{CD|X}|N _ {x,\vec{y}})$ 中得到样本 $\pi _ {Cd|x}^{(t + 1)}$ ，是狄利克雷分布 $Dir (n _ {cdx}^{(t)} + \alpha _ {cd|x}) \qquad n _{cdx}^ {(t)} = \sum _ {\vec{y}:(C=c,D=d) } n _ {x ,\vec{y}}$ 并且，在第三步中，

$$
\pi _ {x|\vec{y}} = \frac {\pi _{x}^{(t + 1)} \pi _{ab|x}^{(t + 1)}\pi_{cd|x}^{(t+1)}} {\sum_x\pi_{x}^{(t+1)} \pi_{ab|x}^{(t + 1)}\pi _{cd|x}^{(t + 1)}}
$$

​         &emsp;如果对N采用泊松或里萨宁先验而不是1/N，则上述算法会稍微复杂一些。大都会-黑斯廷斯台阶上的第2步(大都会-黑斯廷斯-吉布斯内算法)，从 $\pi (N|\theta,n_{0bs} )$ 中采样一个值 $N^{(t + 1)}$ 。 

## 8.5.2 仿真结果

  &emsp;&emsp;在本节中，我们报告模拟的结果，以经验地评估估计算法。

​         &emsp;我们考虑了两种情况:在第一种情况(见图8.2)中，用于生成数据的模型和估计模型在 $[AX],[BX],[CDX]$ 中具有相同的用法。在第二个场景中(见图8.3)，我们通过从模型 $[ABX],[CDX]$ 生成数据并使用模型 $[AX],[BX],[CDX]$ 进行估计来测试模型对错误规范的鲁棒性。对于每个场景，我们生成了两个具有两种不同总体规模的数据集:一个是N = 500，一个是N = 1,000,000。在每个场景的生成模型中，我们设 $\pi_{0}^{X} = 0.4$ ，即范围外单位(包括捕获和未捕获)的比例为40%，未观测单位(包括范围内和范围外)的比例为23%。在情景2中唯一的区别是A和B之间存在一种关系式的相互作用，特别是，在X = 1和X = 0下，A和B的相关性约为0.6，而在estimating配对模型中，它们是条件独立的。

![](D:\bigdata21\tupian.png)

**图8.2**

​         &emsp;情景1中 $N_1$ 的后验分布。N=500(左图)和N=1,000,000(右图)，非信息先验(上图)和信息先验(下图)的结果。实线表示的真实值 $N_1$ ,虚线为最大似然估计值 $N_1$ .

​         &emsp;为了评估先验分布对估计的影响，我们设置了两个案例。在第一种方法中，我们为所有参数(所有狄利克雷参数等于1且P (N) = 1/N)设置非信息先验。在第二种方法中，我们模拟来自审计样本的信息场景:我们从生成的完整总体 $[XABCD]$ 中选取5%的样本，并将狄利克雷参数(parameter)设置为与该样本中观察到的计数相等。此外,为了模拟N的信息先验，我们设置泊松分布为情景2中 $N_1$ 的后验分布。N=500(左图)和N=1,000,000(右图)的结果，非信息先验(上图)，以及信息先验(底部图表)。实线表示 $N_1$ 的真实值(当N=1,000,000时不可见)，虚线表示最大似然估计( $N_1$ )。

![](D:\bigdata21\微信图片_20230329204824.png)

**图8.3**

​        &emsp;在图8.3中我们可以看到，当总体规模不是太大(N = 500)时，正确的信息先验可以有效地缓解估计中缺少参数所带来的误差模型。当总体规模较大(N=1,000,000)时，即使信息先验在正确的方向上影响了后验，它们的贡献似乎不足以弥补缺失的参数(至少在我们介绍的情况下是这样)。事实上 $N_1$ (600,000)的真实值甚至没有包含在99%最高后验密度区间中。
